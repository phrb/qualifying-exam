\chapter{Introduction}
\label{chap:introduction}

The search for more computational power leads to a series of challenges.
Quantum tunneling effects and the speed of light influence the size of
transistors and the length of circuits, and compel the development of
multi-core and heterogeneous computer architectures.  Battery life and a
responsible use of natural resources influence circuit frequency and power
consumption, and compel the development of dynamic frequency scaling and
cooling solutions.  Comparably, the selection and configuration of the
algorithms and computer architectures influence the performance they achieve,
and compel the development of automated selection and configuration solutions.

The use of heterogeneous programming models and computer architectures in High
Performance Computing has increased despite the difficulty of optimizing and
configuring legacy code, and of developing new solutions for heterogeneous
computing. Due to the great diversity of programming models and architectures,
there is no single optimization strategy that fits all problems and
architectures.

An optimization solution tailored for a specific problem requires time and
expert knowledge. Using general optimizations is faster and cheaper, often at
the cost of application-specific performance improvements. A possible solution
to this trade-off is the automation of the program optimization process.

The automated selection of algorithms and configuration of programs, referred
to as \textit{autotuning} from now on, casts the program optimization problem
as a search problem. The possible configurations and optimizations of a program
are used to compose a \textit{search space}, and searching is done by
evaluating the impact of each configuration on the initial program.  Using the
increasingly available computing power to measure different versions of a
program, an \textit{autotuner} searches for good selections, configurations,
and optimizations. The measurements must quantify a meaningful metric for the
programmer, such as execution time and memory or power consumption.

From the implementation in a high-level programming language to the instruction
selection in code generation, it is possible to expose optimization and
configuration opportunities in various stages of program development and
execution.  The time to measure the results of an optimization choice depends
on the selected stage and on the metric to be optimized.
Some stages are more expensive to measure and therefore to optimize.
For example, access to certain architectures might be costly and limited,
or it may take a long time to solve certain problem instances.

Domain-specific autotuning systems must gather expert knowledge to build
performance models or use tailored search techniques.  Despite achieving good
results for its domain, the work on a domain-specific system must be repeated
if one needs an autotuner for another problem domain. The objective of
domain-agnostic autotuning systems is to reuse the effort of selecting search
techniques and implementing a search space to help build autotuners for
different domains.

In a domain-agnostic system, search techniques gathered from different problem
domains can be added to the system, composing an ensemble.  This search
technique ensemble can contain algorithms from areas such as evolutionary
programming, machine learning, statistics and stochastic local search.
Another distinctive feature of domain-agnostic autotuners enable
the representation of diverse search spaces by providing a comprehensive
set of data types, such as integers, floating-point numbers, permutations
and enumerations.

Current domain-agnostic autotuning systems are not capable of fully leveraging
parallel and distributed computing, and typically rely on multiple evaluations
of program configurations to achieve a good result. As a consequence, it is
still inefficient to use domain-agnostic autotuners in domains were evaluating
a configuration is very expensive, such as supercomputer programming, FPGA
compilation and the co-design of hardware and software.

\section{Expected Contribution}
\label{sec:contributions}

The expected contribution of this work is a domain-agnostic autotuning system
that is capable of leveraging parallel and distributed computing. This system
must be able to aid in different steps of hardware and software development,
and handle expensive-to-measure cases efficiently.  We expect to advance the
state-of-the-art of domain-agnostic autotuning tools, enabling the application
of this strategy in a variety of High-Performance Computing Domains.  We
present NODAL, an open distributed autotuning library written in the Julia
language. NODAL is domain-agnostic, and is capable of running parallel and
distributed search and measurement.

\section{Efforts for a Reproducible and Open Research}

We believe openness and reproducibility are fundamental to the quality of
Computer Science research. We made efforts to ensure our research is
reproducible and open, and we believe these efforts help our conclusions.  In
this section we describe the efforts we made.

To ensure the openness of our research we uploaded the software developed
during and for research to public hosting services. We used version control
tools and made the code available under free software licenses. We also
made available the copyright-free versions of our papers, which is a common
practice in Computer Science. The research we performed is free to be used and
modified by future researchers.

To ensure the reproducibility of our research we included hardware and software
specifications in our reports and papers. We uploaded the code to generate the
data, text, presentations and data visualizations to public hosting services.
This code is also available under free-software licenses. Researchers are able
to reproduce our results if they have access to the architecture and software
we specify.

Unfortunately, not all of our research could be made open. The hardware
implementations for the CPUs, GPUs, FPGAs and most electronic components used
to produce our results are not made available by their manufacturers. Neither
is the software used to generate FPGA hardware from its Verilog specification.
To ensure reproducibility in these cases we disclosed the hardware
vendor-specified names and characteristics, and the versions of closed software
we used.

With these efforts for a reproducible and open research we believe we have
provided a better foundation for our conclusions and expected contributions.

\section{Text Organization}
\label{sec:org}

The remainder of this document is organized as follows.  In
chapter~\ref{chap:autonomous} we present the Algorithm Selection Problem, and
the general architecture of autonomous solvers. This chapter also presents a
literature review on autotuning systems for various problem domains, and
discusses the software architecture of OpenTuner~\cite{ansel2014opentuner}, a
domain-agnostic autotuning framework.  In chapter~\ref{chap:usecases} we
present four autotuning case studies targeting different High-Performance
Computing problems and architectures.  In chapter~\ref{chap:julia} we introduce
NODAL, a domain-agnostic autotuning library written in the Julia language. The
implementation of NODAL is the result of the knowledge acquired during this
period, and it proposes solutions to some of the problems we identified along
the way.  Chapter~\ref{chap:final-summary} summarizes the document, and
appendix~\ref{chap:papers} lists the papers we submitted or published during
the period.
